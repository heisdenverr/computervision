# -*- coding: utf-8 -*-
"""custom_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bv0vzm2OTTSRa_-O5OZHJtAaBD-0TIX9
"""

# %%writefile going_modular/data_setup.py

# """
# Contains functionality for creating Pytorch DataLoader's for Image classification data

# """

# import os
# from torchvision import datasets, transforms
# from torch.utils.data import DataLoader

# NUM_WORKERS = os.cpu_count()
# BATCH_SIZE = 32

# def create_dataloaders(
#     train_dir: str,
#     test_dir: str,
#     transform: transforms.Compose,
#     batch_size: int,
#     num_workers: int=NUM_WORKERS):

#   """ Creates training and testing DataLoaders.

#   Takes in a training directory and testing directory path and turns them into
#   Pytorch Datasets and then into PyTorch DataLoaders.

#   Args:
#   train_dir: str, path to the training directory.
#   test_dir: str, path to the testing directory.
#   transform: transforms.Compose, a composition of image transformations to apply.
#   batch_size: int, batch per dataloader [32, 64, 128]
#   num_workers: int, number of workers for the DataLoader.

#   Returns:
#   A tuple of (train_dataloader, test_dataloader, class_names).
#   Where class_names is a list of the target classes.
#   Example usage:
#       train_dataloader, test_dataloader, class_names = create_dataloaders(train_dir=path,
#       test_dir=path,
#       transforms=some_transform,
#       batch_size=32,
#       num_workers=4)

#   """
#   train_directory , test_directory = train_dir, test_dir

#   data_transform = transforms.Compose([
#       transforms.Resize(size=(64, 64)),
#       transforms.ToTensor()
#       ])

#   train_data = datasets.ImageFolder(
#       root=train_directory,
#       trasform=data_transform,
#       target_transform=None
#   )
#   test_data = datasets.ImageFolder(
#       root=test_directory,
#       transform=data_transform
#   )

#   train_dataloader = DataLoader(
#       dataset=train_data,
#       batch_size=BATCH_SIZE,
#       num_workers=NUM_WORKERS,
#       shuffle=True
#   )
#   test_dataloader = DataLoader(
#       dataset=test_data,
#       batch_size=BATCH_SIZE,
#       num_workers=NUM_WORKERS,
#       shuffle=False
#   )

#   class_names = train_data.classes
#   class_idx = train_data.class_to_idx
#   return train_dataloader, test_dataloader, class_names

!nvidia-smi

import os

try:
  if not os.mkdir("going_modular").exists():
    os.mkdir("going_modular")

except:
  print("going_modular already exist")

import requests
import zipfile
from pathlib import Path

data_path = Path("data/")
image_path = data_path / "3foods"

if image_path.exists():
  print("Data already exists")
else:
  print("Loading data")
  image_path.mkdir(parents=True, exist_ok=True)

  with open(data_path / "3foods.zip", "wb") as f:
    request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip")
    print("Downloading.....")
    f.write(request.content)

  with zipfile.ZipFile(data_path / "3foods.zip", "r") as zipr:
    print("Unzipping,,,,,")
    zipr.extractall(image_path)

"""## 2.Becoming one with the data"""

from posixpath import dirname
import os

def walk_through_dir(dir_path):

  for dirpath, dirnames, filenames in os.walk(dir_path):
    print(f"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.")

walk_through_dir(image_path)

train_dir = image_path / 'train'
test_dir = image_path / 'test'
train_dir, test_dir

#!pip install pillow

import random
from PIL import Image

#random.seed(42)

image_path_list = list(image_path.glob("*/*/*.jpg"))

random_image_path = random.choice(image_path_list)
print(random_image_path)

image_class = random_image_path.parent.stem
print(image_class)

img = Image.open(random_image_path)

print(f"Image class: {image_class}")
print(f"Image height: {img.height}")
print(f"Image width: {img.width}")
img

print(image_path_list)

import matplotlib.pyplot as plt
import numpy as np

n_img = np.asarray(img)
print(repr(img))

imgplot = plt.imshow(n_img)
plt.axis(False);

n_img

import torch
from torch.utils.data import DataLoader
from torchvision import transforms, datasets

data_transform = transforms.Compose(
    [
        transforms.Resize(size=(64,64)),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.ToTensor()
    ]
)

data_transform

data_transform(img).shape

data_transform(img).dtype

data_transform(img)

def plot_transformed_images(image_paths: list, transform, n=3, seed=None):
  if seed:
    random.seed(seed)
  random_image_paths = random.sample(image_paths, k=n)
  for image_path in random_image_paths:
    with Image.open(image_path) as f:
      fig, ax = plt.subplots(1, 2)
      print(ax[0])
      ax[0].imshow(f)
      ax[0].set_title(f"Original\nSize: {f.size}")
      ax[0].axis('off')

      transformed_image = transform(f).permute(1, 2, 0)
      ax[1].imshow(transformed_image)
      ax[1].set_title(f"Transformed\nShape: {transformed_image.shape}")
      ax[1].axis('off')

      fig.suptitle(f"Class: {image_path.parent.stem}", fontsize=16)

plot_transformed_images(image_path_list, data_transform, seed=42)

train_data = datasets.ImageFolder(
    root=train_dir,
    transform=data_transform,
    target_transform=None
)

test_data = datasets.ImageFolder(
    root=test_dir,
    transform=data_transform,
)


train_data, test_data

class_names = train_data.classes
class_names

class_dict = train_data.class_to_idx
class_dict

len(train_data), len(test_data)

device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

img, label = train_data[0][0], train_data[0][1]
img.shape, img.dtype, label, type(label)

img_permute = img.permute(1, 2, 0)
plt.imshow(img_permute)
plt.axis('off')
plt.title(class_names[label])

BATCH_SIZE = 32

train_dataloader = DataLoader(
    dataset=train_data,
    batch_size=BATCH_SIZE,
    num_workers=1,
    shuffle=True)

test_dataloader = DataLoader(
    dataset=test_data,
    batch_size=BATCH_SIZE,
    num_workers=1,
    shuffle=False)

train_dataloader, test_dataloader

len(train_dataloader), len(test_dataloader)

img, label = next(iter(train_dataloader))
img.shape, label.shape

import os
os.cpu_count()

class_names[train_data[0][1]]

train_data[0][1]



# Commented out IPython magic to ensure Python compatibility.
# %%writefile going_modular/data_setup.py
# """
# Contains functionality for creating PyTorch DataLoaders for
# image classification data.
# """
# import os
# 
# from torchvision import datasets, transforms
# from torch.utils.data import DataLoader
# 
# NUM_WORKERS = os.cpu_count()
# 
# def create_dataloaders(
#     train_dir: str,
#     test_dir: str,
#     transform: transforms.Compose,
#     batch_size: int,
#     num_workers: int=NUM_WORKERS
# ):
#   """Creates training and testing DataLoaders.
# 
#   Takes in a training directory and testing directory path and turns
#   them into PyTorch Datasets and then into PyTorch DataLoaders.
# 
#   Args:
#     train_dir: Path to training directory.
#     test_dir: Path to testing directory.
#     transform: torchvision transforms to perform on training and testing data.
#     batch_size: Number of samples per batch in each of the DataLoaders.
#     num_workers: An integer for number of workers per DataLoader.
# 
#   Returns:
#     A tuple of (train_dataloader, test_dataloader, class_names).
#     Where class_names is a list of the target classes.
#     Example usage:
#       train_dataloader, test_dataloader, class_names = \
#         = create_dataloaders(train_dir=path/to/train_dir,
#                              test_dir=path/to/test_dir,
#                              transform=some_transform,
#                              batch_size=32,
#                              num_workers=4)
#   """
#   # Use ImageFolder to create dataset(s)
#   train_data = datasets.ImageFolder(train_dir, transform=transform)
#   test_data = datasets.ImageFolder(test_dir, transform=transform)
# 
#   # Get class names
#   class_names = train_data.classes
# 
#   # Turn images into data loaders
#   train_dataloader = DataLoader(
#       train_data,
#       batch_size=batch_size,
#       shuffle=True,
#       num_workers=num_workers,
#       pin_memory=True,
#   )
#   test_dataloader = DataLoader(
#       test_data,
#       batch_size=batch_size,
#       shuffle=False, # don't need to shuffle test data
#       num_workers=num_workers,
#       pin_memory=True,
#   )
# 
#   return train_dataloader, test_dataloader, class_names

from going_modular import data_setup

train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,
                                                                               test_dir=test_dir,
                                                                               transform=data_transform,
                                                                               batch_size=32)
train_dataloader, test_dataloader, class_names

import pathlib
import os
import torch

from PIL import Image
from torch.utils.data import Dataset
from torchvision import transforms
from typing import Tuple, Dict, List

train_data.classes, train_data.class_to_idx

"""**Create a helper functions to replicate imagefolder .classes, .class_to_idx**"""

target_directory = train_dir
print(f"target_directory: {target_directory}")

class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])

class_names_found

for i in os.scandir(target_directory):
  print(i.name)

def find_classes(directory: str)-> Tuple[list[str], Dict[str, int]]:
  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())

  if not classes:
    raise FileNotFoundError(f"Directory {directory} does not contain any directories")


  classes_to_idx = {c : i for i, c in enumerate(classes)}


  return classes, classes_to_idx

find_classes(target_directory)

find_classes(test_dir)

from torch.utils.data import Dataset

class ImageFolderCustom(Dataset):

  def __init__(self, targ_dir: str, transform=None):

    self.paths = list(pathlib.Path(targ_dir).glob("*/*.jpg"))
    self.transform = transform
    self.classes, self.class_to_idx = find_classes(targ_dir)

  def load_image(self, index: int) -> Image.Image:
    image_path = self.paths[index]
    return Image.open(image_path)

  def __len__(self):
    return len(self.paths)

  def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:
    img = self.load_image(index)
    class_name = self.paths[index].parent.name
    class_idx = self.class_to_idx[class_name]

    if self.transform:
      return self.transform(img), class_idx
    else:
      return img, class_idx

train_transforms = transforms.Compose([
    transforms.Resize(size=(64, 64)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor()
])

test_transforms = transforms.Compose([
    transforms.Resize(size=(64, 64)),
    transforms.ToTensor()
])

train_data_custom = ImageFolderCustom(
    targ_dir=train_dir,
    transform=train_transforms
)

test_data_custom = ImageFolderCustom(
    targ_dir=test_dir,
    transform=test_transforms
)

len(train_data_custom), len(test_data_custom)

train_data_custom.classes

train_data_custom.class_to_idx

print(train_data_custom.classes==train_data.classes)
print(test_data_custom.classes==test_data.classes)

def display_random_images(dataset: torch.utils.data.Dataset,
                          classes: List[str]=None,
                          n: int = 10,
                          display_shape: bool = True,
                          seed: int = None):
  if n > 10:
    n = 10
    display_shape = False
    print("n must be less than 10")
  if seed:
    random.seed(seed)

  random_sample_idx = random.sample(range(len(dataset)), k=n)

  plt.figure(figsize=(16, 8))

  for i, targ_sample in enumerate(random_sample_idx):
    targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]

    targ_image_adjust = targ_image.permute(1, 2, 0)
    plt.subplot(1, n, i+1)
    plt.imshow(targ_image_adjust)
    plt.axis('off')
    if classes:
      title = f"Class: {classes[targ_label]}"
      if display_shape:
        title += f"\nShape: {targ_image_adjust.shape}"
    plt.title(title)

display_random_images(train_data, n=5, classes=class_names, seed=12937)

from torch.utils.data import  DataLoader
BATCH_SIZE = 32
NUM_WORKERS = os.cpu_count()
train_dataloader_custom = DataLoader(
    dataset=train_data_custom,
    batch_size=BATCH_SIZE,
    num_workers=NUM_WORKERS,
    shuffle=True
)

test_dataloader_custom = DataLoader(
    dataset=test_data_custom,
    batch_size=BATCH_SIZE,
    num_workers=NUM_WORKERS,
    shuffle=False
)

train_dataloader_custom, test_dataloader_custom

img_custom, label_custom = next(iter(train_dataloader_custom))

img_custom.shape, label_custom.shape

print(type(label_custom))

label_custom

img_custom.shape

from torchvision import transforms

train_transform = transforms.Compose([
    transforms.Resize(size=(224, 224)),
    transforms.TrivialAugmentWide(num_magnitude_bins=31),
    transforms.ToTensor()
])

test_transform = transforms.Compose([
    transforms.Resize(size=(224, 224)),
    transforms.ToTensor()
])

image_path

train_transform

image_path_list = list(image_path.glob("*/*/*.jpg"))
image_path_list[:10]

plot_transformed_images(
    image_paths=image_path_list,
    transform=train_transform,
    n=3,
    seed=None
)

train_transforms

simple_transform = transforms.Compose([
    transforms.Resize(size=(64, 64)),
    transforms.ToTensor()
])

simple_train_data = ImageFolderCustom(
    targ_dir=train_dir,
    transform=simple_transform
)

simple_test_data = ImageFolderCustom(
    targ_dir=test_dir,
    transform=simple_transform
)

simple_train_loader = DataLoader(
    dataset=simple_train_data,
    batch_size=BATCH_SIZE,
    num_workers=NUM_WORKERS,
    shuffle=True
)

simple_test_loader = DataLoader(
    dataset=simple_test_data,
    batch_size=BATCH_SIZE,
    num_workers=NUM_WORKERS,
    shuffle=False
)

simple_image, simple_label = next(iter(simple_train_loader))
simple_image.shape, simple_label.shape

train_data_simple = datasets.ImageFolder(
    root=train_dir,
    transform=simple_transform
)

test_data_simple = datasets.ImageFolder(
    root=test_dir,
    transform=simple_transform
)

train_dataloader_simple = DataLoader(
    dataset=train_data_simple,
    batch_size=BATCH_SIZE,
    num_workers=NUM_WORKERS,
    shuffle=True
)

test_dataloader_simple = DataLoader(
    dataset=test_data_simple,
    batch_size=BATCH_SIZE,
    num_workers=NUM_WORKERS,
    shuffle=False
)

from torch import nn

class TinyVGG(nn.Module):

  def __init__(self, input_shape: int,
               hidden_units: int,
               output_shape: int) -> None:
    super().__init__()
    self.conv_block_1 = nn.Sequential(
        nn.Conv2d(in_channels=input_shape,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=0),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
    )
    self.conv_block_2 = nn.Sequential(
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=0),
        nn.ReLU(),
        nn.Conv2d(in_channels=hidden_units,
                  out_channels=hidden_units,
                  kernel_size=3,
                  stride=1,
                  padding=0),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
    )

    self.classifier = nn.Sequential(
        nn.Flatten(),
        nn.Linear(in_features = hidden_units*13*13,
                  out_features=len(class_names))
    )

  def forward(self, x: torch.Tensor):
    # x = self.conv_block_1(x)
    # print(x.shape)
    # x = self.conv_block_2(x)
    # print(x.shape)
    # x = self.classifier(x)
    # print(x.shape)
    # return x
    return self.classifier(self.conv_block_2(self.conv_block_1(x)))

# Commented out IPython magic to ensure Python compatibility.
# %%writefile going_modular/model_builder.py
# """
# Contains PyTorch model code to instantiate a TinyVGG model.
# """
# import torch
# from torch import nn
# 
# class TinyVGG(nn.Module):
#   """Creates the TinyVGG architecture.
# 
#   Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.
#   See the original architecture here: https://poloclub.github.io/cnn-explainer/
# 
#   Args:
#     input_shape: An integer indicating number of input channels.
#     hidden_units: An integer indicating number of hidden units between layers.
#     output_shape: An integer indicating number of output units.
#   """
#   def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:
#       super().__init__()
#       self.conv_block_1 = nn.Sequential(
#           nn.Conv2d(in_channels=input_shape,
#                     out_channels=hidden_units,
#                     kernel_size=3,
#                     stride=1,
#                     padding=0),
#           nn.ReLU(),
#           nn.Conv2d(in_channels=hidden_units,
#                     out_channels=hidden_units,
#                     kernel_size=3,
#                     stride=1,
#                     padding=0),
#           nn.ReLU(),
#           nn.MaxPool2d(kernel_size=2,
#                         stride=2)
#       )
#       self.conv_block_2 = nn.Sequential(
#           nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),
#           nn.ReLU(),
#           nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),
#           nn.ReLU(),
#           nn.MaxPool2d(2)
#       )
#       self.classifier = nn.Sequential(
#           nn.Flatten(),
#           # Where did this in_features shape come from?
#           # It's because each layer of our network compresses and changes the shape of our inputs data.
#           nn.Linear(in_features=hidden_units*13*13,
#                     out_features=output_shape)
#       )
# 
#   def forward(self, x: torch.Tensor):
#     x = self.conv_block_1(x)
#     x = self.conv_block_2(x)
#     x = self.classifier(x)
#     return x
#     # return self.classifier(self.conv_block_2(self.conv_block_1(x)))

from going_modular import model_builder

import torch
# Import model_builder.py
from going_modular import model_builder
device = "cuda" if torch.cuda.is_available() else "cpu"

# Instantiate an instance of the model from the "model_builder.py" script
torch.manual_seed(42)
model = model_builder.TinyVGG(input_shape=3,
                              hidden_units=10,
                              output_shape=3).to(device)

model.eval()
with torch.inference_mode():
  pred = model(custom_transformed.unsqueeze(0).to(device))
  pred_pr = torch.argmax(torch.softmax(pred, dim=1), dim=1)
  print(f"{class_names[pred_pr]}")

torch.manual_seed(42)
model_0 = TinyVGG(input_shape=3,
                  hidden_units=10,
                  output_shape=len(class_names)).to(device)
model_0

image_batch, label_batch = next(iter(train_dataloader_simple))
image_batch.shape, label_batch.shape

len(image_batch)

model_0(image_batch.to(device))

try:
  import torchinfo
except:
  !pip install torchinfo

from torchinfo import summary

summary(model_0,
        input_size=(1, 3, 64, 64))

def train_step(model: torch.nn.Module,
               dataloader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               optimizer: torch.optim.Optimizer,
               device=device):
  model.train()

  train_loss, train_acc = 0, 0

  for batch, (X, y) in enumerate(dataloader):

    X, y = X.to(device), y.to(device)

    y_pred = model(X)

    loss = loss_fn(y_pred, y)
    train_loss += loss.item()

    optimizer.zero_grad()

    loss.backward()
    optimizer.step()

    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
    train_acc += (y_pred_class == y).sum().item()/ len(y_pred)

  train_loss = train_loss/ len(dataloader)
  train_acc = train_acc/ len(dataloader)
  return train_loss, train_acc

def test_step(model: torch.nn.Module,
              dataloader: torch.utils.data.DataLoader,
              loss_fn: torch.nn.Module,
              device=device):
  model.eval()

  test_loss, test_acc = 0, 0

  with torch.inference_mode():

    for batch, (X, y) in enumerate(dataloader):
      X, y = X.to(device), y.to(device)

      test_pred_logits = model(X)

      loss = loss_fn(test_pred_logits, y)
      test_loss += loss.item()

      test_pred_labels = test_pred_logits.argmax(dim=1)
      test_acc += (test_pred_labels == y).sum().item()/len(test_pred_labels)

  test_loss = test_loss/ len(dataloader)
  test_acc = test_acc/ len(dataloader)
  return test_loss, test_acc

from tqdm.auto import tqdm

def train(model: torch.nn.Module,
          train_dataloader: torch.utils.data.DataLoader,
          test_dataloader: torch.utils.data.DataLoader,
          optimizer: torch.optim.Optimizer,
          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),
          epochs: int = 10,
          device= device):

  results = {"train_loss": [],
             "train_acc": [],
             "test_loss": [],
             "test_acc": []}

  for epoch in tqdm(range(epochs)):
    train_loss, train_acc = train_step(model=model,
                                       dataloader=train_dataloader,
                                       loss_fn=loss_fn,
                                       optimizer=optimizer,
                                       device=device)
    test_loss, test_acc = test_step(model=model,
                                   dataloader=test_dataloader,
                                   loss_fn=loss_fn,
                                   device=device)
    print(f"Epoch: {epoch} | train_loss: {train_loss:.4f} | train_acc: {train_acc:.4f} | test_loss: {test_loss:.4f} | test_acc: {test_acc:.4f}")

    results["train_loss"].append(train_loss)
    results["train_acc"].append(train_acc)
    results["test_loss"].append(test_loss)
    results["test_acc"].append(test_acc)


  return results

torch.manual_seed(42)
torch.cuda.manual_seed(42)

NUM_EPOCHS = 10
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params=model_0.parameters(),
                            lr=1e-3)

from timeit import default_timer as timer
start_time = timer()

model_0_results = train(model=model_0,
                        train_dataloader=train_dataloader_simple,
                        test_dataloader=test_dataloader_simple,
                        optimizer=optimizer,
                        loss_fn=loss_fn,
                        epochs=NUM_EPOCHS
                        )
end_time = timer()
print(f"Total training time: {end_time-start_time:.3f} seconds")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile going_modular/train.py
# 
# """
# Trains a Pytorch image classification model using device-agnostic code
# """
# import os
# import torch
# from torchvision import transforms
# import data_setup, engine, utils, model_builder
# from timeit import default_timer as timer
# 
# NUM_EPOCHS = 5
# BATCH_SIZE = 32
# HIDDEN_UNITS = 10
# LEARNING_RATE = 1e-3
# 
# train_dir = "data/3foods/train"
# test_dir = "data/3foods/test"
# 
# device = "cuda" if torch.cuda.is_available() else "cpu"
# 
# data_transform = transforms.Compose([
#     transforms.Resize(size=(64, 64)),
#     transforms.ToTensor()
# ])
# 
# train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,
#                                                                                test_dir=test_dir,
#                                                                                transform=data_transform,
#                                                                                batch_size=BATCH_SIZE,
#                                                                               )
# model = model_builder.TinyVGG(input_shape=3,
#                               hidden_units=10,
#                               output_shape=len(class_names)).to(device)
# 
# 
# loss_fn = torch.nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)
# 
# 
# start_time = timer()
# 
# engine.train(model=model,
#              train_dataloader=train_dataloader,
#              test_dataloader=test_dataloader,
#              loss_fn=loss_fn,
#              optimizer=optimizer,
#              epochs=NUM_EPOCHS,
#              device=device)
# 
# end_time = timer()
# print(f"Total training time: {end_time-start_time:.3f} seconds")
# 
# utils.save_model(model=model,
#                  target_dir="models",
#                  model_name="05_scripting_TinyVGG.pth")

!python going_modular/train.py

def predict(image):

model_0_results.keys()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile going_modular/engine.py
# """
# Contains functions for training and testing a PyTorch model.
# """
# import torch
# 
# from tqdm.auto import tqdm
# from typing import Dict, List, Tuple
# 
# def train_step(model: torch.nn.Module,
#                dataloader: torch.utils.data.DataLoader,
#                loss_fn: torch.nn.Module,
#                optimizer: torch.optim.Optimizer,
#                device: torch.device) -> Tuple[float, float]:
#   """Trains a PyTorch model for a single epoch.
# 
#   Turns a target PyTorch model to training mode and then
#   runs through all of the required training steps (forward
#   pass, loss calculation, optimizer step).
# 
#   Args:
#     model: A PyTorch model to be trained.
#     dataloader: A DataLoader instance for the model to be trained on.
#     loss_fn: A PyTorch loss function to minimize.
#     optimizer: A PyTorch optimizer to help minimize the loss function.
#     device: A target device to compute on (e.g. "cuda" or "cpu").
# 
#   Returns:
#     A tuple of training loss and training accuracy metrics.
#     In the form (train_loss, train_accuracy). For example:
# 
#     (0.1112, 0.8743)
#   """
#   # Put model in train mode
#   model.train()
# 
#   # Setup train loss and train accuracy values
#   train_loss, train_acc = 0, 0
# 
#   # Loop through data loader data batches
#   for batch, (X, y) in enumerate(dataloader):
#       # Send data to target device
#       X, y = X.to(device), y.to(device)
# 
#       # 1. Forward pass
#       y_pred = model(X)
# 
#       # 2. Calculate  and accumulate loss
#       loss = loss_fn(y_pred, y)
#       train_loss += loss.item()
# 
#       # 3. Optimizer zero grad
#       optimizer.zero_grad()
# 
#       # 4. Loss backward
#       loss.backward()
# 
#       # 5. Optimizer step
#       optimizer.step()
# 
#       # Calculate and accumulate accuracy metric across all batches
#       y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
#       train_acc += (y_pred_class == y).sum().item()/len(y_pred)
# 
#   # Adjust metrics to get average loss and accuracy per batch
#   train_loss = train_loss / len(dataloader)
#   train_acc = train_acc / len(dataloader)
#   return train_loss, train_acc
# 
# def test_step(model: torch.nn.Module,
#               dataloader: torch.utils.data.DataLoader,
#               loss_fn: torch.nn.Module,
#               device: torch.device) -> Tuple[float, float]:
#   """Tests a PyTorch model for a single epoch.
# 
#   Turns a target PyTorch model to "eval" mode and then performs
#   a forward pass on a testing dataset.
# 
#   Args:
#     model: A PyTorch model to be tested.
#     dataloader: A DataLoader instance for the model to be tested on.
#     loss_fn: A PyTorch loss function to calculate loss on the test data.
#     device: A target device to compute on (e.g. "cuda" or "cpu").
# 
#   Returns:
#     A tuple of testing loss and testing accuracy metrics.
#     In the form (test_loss, test_accuracy). For example:
# 
#     (0.0223, 0.8985)
#   """
#   # Put model in eval mode
#   model.eval()
# 
#   # Setup test loss and test accuracy values
#   test_loss, test_acc = 0, 0
# 
#   # Turn on inference context manager
#   with torch.inference_mode():
#       # Loop through DataLoader batches
#       for batch, (X, y) in enumerate(dataloader):
#           # Send data to target device
#           X, y = X.to(device), y.to(device)
# 
#           # 1. Forward pass
#           test_pred_logits = model(X)
# 
#           # 2. Calculate and accumulate loss
#           loss = loss_fn(test_pred_logits, y)
#           test_loss += loss.item()
# 
#           # Calculate and accumulate accuracy
#           test_pred_labels = test_pred_logits.argmax(dim=1)
#           test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))
# 
#   # Adjust metrics to get average loss and accuracy per batch
#   test_loss = test_loss / len(dataloader)
#   test_acc = test_acc / len(dataloader)
#   return test_loss, test_acc
# 
# def train(model: torch.nn.Module,
#           train_dataloader: torch.utils.data.DataLoader,
#           test_dataloader: torch.utils.data.DataLoader,
#           optimizer: torch.optim.Optimizer,
#           loss_fn: torch.nn.Module,
#           epochs: int,
#           device: torch.device) -> Dict[str, List]:
#   """Trains and tests a PyTorch model.
# 
#   Passes a target PyTorch models through train_step() and test_step()
#   functions for a number of epochs, training and testing the model
#   in the same epoch loop.
# 
#   Calculates, prints and stores evaluation metrics throughout.
# 
#   Args:
#     model: A PyTorch model to be trained and tested.
#     train_dataloader: A DataLoader instance for the model to be trained on.
#     test_dataloader: A DataLoader instance for the model to be tested on.
#     optimizer: A PyTorch optimizer to help minimize the loss function.
#     loss_fn: A PyTorch loss function to calculate loss on both datasets.
#     epochs: An integer indicating how many epochs to train for.
#     device: A target device to compute on (e.g. "cuda" or "cpu").
# 
#   Returns:
#     A dictionary of training and testing loss as well as training and
#     testing accuracy metrics. Each metric has a value in a list for
#     each epoch.
#     In the form: {train_loss: [...],
#                   train_acc: [...],
#                   test_loss: [...],
#                   test_acc: [...]}
#     For example if training for epochs=2:
#                  {train_loss: [2.0616, 1.0537],
#                   train_acc: [0.3945, 0.3945],
#                   test_loss: [1.2641, 1.5706],
#                   test_acc: [0.3400, 0.2973]}
#   """
#   # Create empty results dictionary
#   results = {"train_loss": [],
#       "train_acc": [],
#       "test_loss": [],
#       "test_acc": []
#   }
# 
#   # Loop through training and testing steps for a number of epochs
#   for epoch in tqdm(range(epochs)):
#       train_loss, train_acc = train_step(model=model,
#                                           dataloader=train_dataloader,
#                                           loss_fn=loss_fn,
#                                           optimizer=optimizer,
#                                           device=device)
#       test_loss, test_acc = test_step(model=model,
#           dataloader=test_dataloader,
#           loss_fn=loss_fn,
#           device=device)
# 
#       # Print out what's happening
#       print(
#           f"Epoch: {epoch+1} | "
#           f"train_loss: {train_loss:.4f} | "
#           f"train_acc: {train_acc:.4f} | "
#           f"test_loss: {test_loss:.4f} | "
#           f"test_acc: {test_acc:.4f}"
#       )
# 
#       # Update results dictionary
#       results["train_loss"].append(train_loss)
#       results["train_acc"].append(train_acc)
#       results["test_loss"].append(test_loss)
#       results["test_acc"].append(test_acc)
# 
#   # Return the filled results at the end of the epochs
#   return results

from going_modular import engine
engine.train(model=model_0,
            train_dataloader=train_dataloader_simple,
            test_dataloader=test_dataloader_simple,
            optimizer=optimizer,
            loss_fn=loss_fn,
            epochs=NUM_EPOCHS,
            device=device
)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile going_modular/utils.py
# """
# Contains various utility functions for PyTorch model training and saving.
# """
# import torch
# from pathlib import Path
# 
# def save_model(model: torch.nn.Module,
#                target_dir: str,
#                model_name: str):
#   """Saves a PyTorch model to a target directory.
# 
#   Args:
#     model: A target PyTorch model to save.
#     target_dir: A directory for saving the model to.
#     model_name: A filename for the saved model. Should include
#       either ".pth" or ".pt" as the file extension.
# 
#   Example usage:
#     save_model(model=model_0,
#                target_dir="models",
#                model_name="05_going_modular_tingvgg_model.pth")
#   """
#   # Create target directory
#   target_dir_path = Path(target_dir)
#   target_dir_path.mkdir(parents=True,
#                         exist_ok=True)
# 
#   # Create model save path
#   assert model_name.endswith(".pth") or model_name.endswith(".pt"), "model_name should end with '.pt' or '.pth'"
#   model_save_path = target_dir_path / model_name
# 
#   # Save the model state_dict()
#   print(f"[INFO] Saving model to: {model_save_path}")
#   torch.save(obj=model.state_dict(),
#              f=model_save_path)

def plot_loss_curves(results: Dict[str, List[float]]):

  loss = results["train_loss"]
  test_loss = results["test_acc"]

  accuracy = results["train_acc"]
  test_accuracy = results["test_acc"]

  epochs = range(len(results["train_loss"]))

  plt.figure(figsize=(15, 7))

  plt.subplot(1, 2, 1)
  plt.plot(epochs, loss, label="train_loss")
  plt.plot(epochs, test_loss, label="test_loss")
  plt.title("Loss")
  plt.xlabel("Epochs")
  plt.legend()

  plt.subplot(1, 2, 2)
  plt.plot(epochs, accuracy, label="train_accuracy")
  plt.plot(epochs, test_accuracy, label="test_accuracy")
  plt.title("Accuracy")
  plt.xlabel("Epochs")
  plt.legend();

plot_loss_curves(model_0_results)

from torchvision import transforms
train_transforms_trivial = transforms.Compose([
    transforms.Resize(size=(64, 64)),
    transforms.TrivialAugmentWide(num_magnitude_bins=31),
    transforms.ToTensor()
])

test_transform_simple = transforms.Compose([
    transforms.Resize(size=(64, 64)),
    transforms.ToTensor()
])

from torchvision import datasets
train_data_augmented = datasets.ImageFolder(
    root=train_dir,
    transform=train_transforms_trivial
)

test_data_simple = datasets.ImageFolder(
    root=test_dir,
    transform=test_transform_simple
)

import os
from torch.utils.data import DataLoader
BATCH_SIZE = 32
NUM_WORKERS = os.cpu_count()

torch.manual_seed(42)
train_dataloader_augmented = DataLoader(
    dataset=train_data_augmented,
    batch_size=BATCH_SIZE,
    num_workers=NUM_WORKERS,
    shuffle=True
)

test_dataloader_simple = DataLoader(
    dataset=test_data_simple,
    batch_size=BATCH_SIZE,
    num_workers=NUM_WORKERS,
    shuffle=False
)

162/32

img, label = next(iter(train_dataloader_simple))
img, label

"""Making a prediction on a custom image"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile going_modular/predict.py
# 
# import requests
# import torchvision
# from going_modular import model_builder, utils, data_setup, engine, train
# custom_image_path = data_path / "04-pizza-dad.jpeg"
# 
# if not custom_image_path.is_file():
#   with open(custom_image_path, "wb") as f:
#     request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/blob/main/images/04-pizza-dad.jpeg?raw=true")
#     print("Downloading custom image...")
#     f.write(request.content)
# else:
#   print(f"{custom_image_path} already exists")
# 
# 
# 
# custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))/255
# 
# custom_resize = transforms.Compose([
#     transforms.Resize(size=(64, 64))
# ]
# )
# 
# custom_transformed = custom_resize(custom_image_uint8)
# 
# 
# c =custom_transformed.unsqueeze(dim=0)
# 
# torch.manual_seed(42)
# model = model_builder.TinyVGG(input_shape=3,
#                               hidden_units=10,
#                               output_shape=3).to(device)
# def predict():
#   model.eval()
#   with torch.inference_mode():
# 
#     pred = model_0(img[i].unsqueeze(0).to(device))
#     preds = torch.argmax(torch.softmax(pred, dim=1), dim=1)
#     pred_prob = torch.softmax(pred, dim=1)
#     plt.imshow(custom_image_uint8.permute(1,2,0))
#     plt.title(f"{class_names[preds]}, {pred_prob.max():.3f}")
#     plt.axis(False)
#     plt.show();

import torchvision
custom_image_path = data_path / "04-pizza-dad.jpeg"
if not custom_image_path.is_file():
  with open(custom_image_path, "wb") as f:
    request = requests.get("https://github.com/mrdbourke/pytorch-deep-learning/blob/main/images/04-pizza-dad.jpeg?raw=true")
    print("Downloading custom image...")
    f.write(request.content)
else:
  print(f"{custom_image_path} already exists")

custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))/255
custom_image_uint8

plt.imshow(custom_image_uint8.permute(1, 2, 0))

print(f"{custom_image_uint8.shape} \n {custom_image_uint8.dtype}")

device

os.cpu_count()

custom_resize = transforms.Compose([
    transforms.Resize(size=(64, 64))
]
)

custom_transformed = custom_resize(custom_image_uint8)
custom_transformed.shape

plt.imshow(custom_transformed.permute(1, 2, 0))

c =custom_transformed.unsqueeze(dim=0)
c.shape

model_0.eval()
with torch.inference_mode():
  preds = model_0(c.to(device))
preds

custom_transformed.shape

img[:0].shape

model_0.eval()
with torch.inference_mode():
  for i in range(len(img[:5])):
    pred = model_0(img[i].unsqueeze(0).to(device))
    preds = torch.argmax(torch.softmax(pred, dim=1), dim=1)
    pred_prob = torch.softmax(pred, dim=1)
    plt.imshow(custom_image_uint8.permute(1,2,0))
    plt.title(f"{class_names[preds]}, {pred_prob.max():.3f}")
    plt.axis(False)
    plt.show();

class_names

preds = torch.argmax(torch.softmax(pred, dim=1), dim=1)

pred_prob = torch.softmax(pred, dim=1)
pred_prob.max()

plt.imshow(custom_image_uint8.permute(1,2,0))
plt.title(f"{class_names[preds]}, {pred_prob.max():.3f}")
plt.axis(False)
plt.show();

img.shape

"""# New section"""